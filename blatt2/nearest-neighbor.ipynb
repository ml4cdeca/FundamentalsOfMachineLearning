{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"right\">\n",
    "  Christopher Lüken-Winkels, Lukas Blecher\n",
    "</div>\n",
    "# Exercise 1b\n",
    "## 2 Asymptotic error of the nearest neighbor classifier for the toy example from exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align}\n",
    "p_∞(error|X) = 1 -\\sum_{k=1} p^∗ (Y = k | X)^2 &&&& \\text{(1)}\\\\\n",
    "p^*(Y=1|X)=X&&&& \\text{(2)}\\\\\n",
    "p^*(Y=0|X)=1-X&&&& \\text{(3)}\\\\\n",
    "p(X)=1&&&& \\text{(4)}\n",
    "\\end{align}$$\n",
    "Now solve the following integral: $$p_\\infty(\\text{error})=\\int p_\\infty(\\text{error}|X)p(X)dX \\stackrel{\\text{(1)}}{=}\\int \\left( \\sum_{k=1} p^*(Y=k|X)^2 \\right)p(X)dX \\stackrel{\\text{(2),(3),(4)}}{=}\\int \\left( 1-X^2-X^2+2X-1\\right)dX= \\int_0^1 \\left(2X-2X^2\\right)dX=\\left(X^2-\\frac23X^3\\right) \\biggr\\rvert^1_0=1-\\frac23=\\frac13$$\n",
    "In exersize 1 we already approximated an error of about 33% for training sets of size 100, which confirms the theoretical solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Nearest Neighbor Classification on Real Data\n",
    "### 3.1 Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "digits = load_digits ()\n",
    "print ( digits.keys () )\n",
    "data = digits [\"data\"]\n",
    "images = digits [\"images\"]\n",
    "target = digits [\"target\"]\n",
    "target_names = digits [\"target_names\"]\n",
    "print ( data.dtype )\n",
    "#get an image of a random \"3\":\n",
    "threes=images[target==3] #could also use data[index].reshape((8,8)) \n",
    "img=threes[np.random.randint(len(threes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert 2 == len( img.shape )\n",
    "plt.figure ()\n",
    "plt.gray ()\n",
    "plt.imshow (img , interpolation =\"bicubic\") # also try interpolation =\" bicubic \"\n",
    "plt.title('3')\n",
    "plt.show ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "X_all = data[7:] #needs to be divisible by 10 for later to work\n",
    "y_all = target[7:]\n",
    "X_train , X_test , y_train , y_test =\\\n",
    "model_selection.train_test_split ( digits.data , digits.target ,test_size = 0.4 , random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Distance function computation using loops\n",
    "$$\\text{dist:}\\ {\\rm I\\!R}^{N \\times D} \\times {\\rm I\\!R}^{M \\times D} \\rightarrow {\\rm I\\!R}^{N \\times M}$$ with $$N \\text{: Length of training set}\\\\M \\text{: Lenght of test set}\\\\D \\text{: Number of pixels} = 64$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist_loop(training, test):\n",
    "    d=[] #save distances in this matrix\n",
    "    #now: fill matrix line by line\n",
    "    for i in range(len(training)):\n",
    "        line=[] \n",
    "        #fill line for line with the distances\n",
    "        for j in range(len(test)):\n",
    "            line.append(np.sqrt(np.sum(np.square(test[j]-training[i]))))\n",
    "        d.append(line)\n",
    "    return np.array(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Distance function computation using vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist_vec(training, test):\n",
    "    #adding a new dimension to sum over (pixels) and calculate the difference to the test set in each instance\n",
    "    return np.sqrt(np.sum(np.square(training[:,None]-test),axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit dist_loop(X_test,X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit dist_vec(X_test,X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check if both function even do the same\n",
    "np.array_equal(dist_vec(X_test,X_train),dist_loop(X_test,X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the vectorized solution is way faster than the looped version and gives the same result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Implement the k-nearest neighbor classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define the subset of X_train\n",
    "subX_train=X_train[(y_train==3) | (y_train==9)] #only 3's and 9's are in the subsets\n",
    "subX_test=X_test[(y_test==3) | (y_test==9)]\n",
    "subY_train=y_train[(y_train==3) | (y_train==9)]\n",
    "subY_test=y_test[(y_test==3) | (y_test==9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nearest neighbor classifier\n",
    "def NN(k,training,test,trainingLabel,testLabel):\n",
    "    #calculate the distance matrix\n",
    "    distance=dist_vec(training,test)\n",
    "    guess=[]\n",
    "    for i in range(len(test)):\n",
    "        #get indices of smallest k distances of each column\n",
    "        sorting=np.argsort(distance,axis=0).T[i][:k]\n",
    "        #take the mean of all neighbors and see what integer is the most likley\n",
    "        guess.append(round(np.mean(trainingLabel[sorting])))\n",
    "    error=1-np.count_nonzero(np.equal(guess,testLabel))/len(testLabel)\n",
    "    return error,np.array(guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "try for $k \\in [ 1, 3, 5, 9, 17,33]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "err=[]\n",
    "for k in [1,3,5,9,17,33]:\n",
    "    errK,result=NN(k,subX_train,subX_test,subY_train,subY_test)\n",
    "    err.append(errK)\n",
    "print(np.mean(err),np.std(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in average we get an error rate for $(1.0\\pm 0.5)$%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1LIUJEmt/w9TLqJkuwU1iAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([1,3,5,9,17,33],err,'.',label='error rate')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('error')\n",
    "plt.title('error as function of k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the error is growing with $k$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import random as rnd\n",
    "\n",
    "def split_folds(data, target, L):   \n",
    "    #shuffle target and data in unison\n",
    "    permutation = rnd.permutation(len(data))\n",
    "    data,target = data[permutation],target[permutation]\n",
    "    return np.array(np.array_split(data,L)),np.array(np.array_split(target,L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_val(data,target,L,k):   #only works if len(data)%L == 0\n",
    "    if len(data)%L!=0:\n",
    "        raise ValueError('Only works with denominators of the data length')\n",
    "    #start list for error values\n",
    "    Err = []\n",
    "    #split data\n",
    "    X_folds,Y_folds = split_folds(data,target,L)\n",
    "    #use each fold as test data once and the remaining folds as training set\n",
    "    for i in range(L):\n",
    "        X_test,Y_test = X_folds[i],Y_folds[i]\n",
    "        X_train,Y_train = np.delete(X_folds,i,axis=0),np.delete(Y_folds,i,axis=0).flatten() #training set without test set\n",
    "        X_train=np.array(list(itertools.chain(*X_train))) #combine packs to one big pack\n",
    "        err,guess = NN(k, X_train, X_test, Y_train, Y_test)\n",
    "        Err.append(err)\n",
    "    return np.mean(Err),np.std(Err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.086111111111111124, 0.036111111111111094)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subX_all = X_all[(y_all==3) | (y_all==9)][2:] #only 3's and 9's are in the subsets\n",
    "suby_all = y_all[(y_all==3) | (y_all==9)][2:] #remove 2 so that len(subX_all)%10=0\n",
    "cross_val(subX_all,suby_all,10,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in average we get an error rate for $(0.8\\pm 1.3)$%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we implement the pre-defined solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "def skNN(k,training,trainingLabel,test,testLabel):\n",
    "    classifier= KNeighborsClassifier(n_neighbors=k)\n",
    "    classifier.fit(training,trainingLabel) #train with the same data as in 3.4\n",
    "    skGuess=classifier.predict(test)\n",
    "    Error=1-np.count_nonzero(np.equal(skGuess,testLabel))/len(testLabel)\n",
    "    return Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def skcross_val(data,target,L,k):   #only works if len(data)%L == 0\n",
    "    if len(data)%L!=0:\n",
    "        raise ValueError('Only works with denominators of the data length')\n",
    "    #start list for error values\n",
    "    Err = []\n",
    "    #split data\n",
    "    X_folds,Y_folds = split_folds(data,target,L)\n",
    "    #use each fold as test data once and the remaining folds as training set\n",
    "    for i in range(L):\n",
    "        X_test,Y_test = X_folds[i],Y_folds[i]\n",
    "        X_train,Y_train = np.delete(X_folds,i,axis=0),np.delete(Y_folds,i,axis=0).flatten() #training set without test set\n",
    "        X_train=np.array(list(itertools.chain(*X_train))) #combine packs to one big pack\n",
    "        err = skNN(k,X_train, Y_train, X_test, Y_test)\n",
    "        Err.append(err)\n",
    "    return np.mean(Err),np.std(Err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skcross_val(subX_all,suby_all,10,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the sklearn algorithm handles the problem better than our implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate the error and std for L=2,5,10 and for k=1,5 for both algorithms \n",
    "for algorithm in [cross_val,skcross_val]:\n",
    "    for k in [1,5]:\n",
    "        error,delErr=[],[]\n",
    "        for L in [2,5,10]:\n",
    "            e,d=algorithm(X_all,y_all,L,k)\n",
    "            error.append(e)\n",
    "            delErr.append(d)\n",
    "        plt.errorbar([2,5,10],err,yerr=delErr,capsize=2,label='%s for $k=%i'%(['ours','sklearn'],k))\n",
    "plt.title(\"Comparison of the algorithm's performance\")\n",
    "plt.xlabel('L')\n",
    "plt.ylabel('error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
