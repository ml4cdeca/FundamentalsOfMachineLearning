{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4a\n",
    "## 3 Red Cards Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1  Loading and Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load data with pandas\n",
    "data=pd.read_csv('data/CrowdstormingDataJuly1st.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "playerShort                toni-kroos\n",
       "player                     Toni Kroos\n",
       "club                   Bayern MÃ¼nchen\n",
       "leagueCountry                 Germany\n",
       "birthday                   04.01.1990\n",
       "height                            182\n",
       "weight                             78\n",
       "position         Attacking Midfielder\n",
       "games                               1\n",
       "victories                           1\n",
       "ties                                0\n",
       "defeats                             0\n",
       "goals                               0\n",
       "yellowCards                         0\n",
       "yellowReds                          0\n",
       "redCards                            0\n",
       "photoID                     84724.jpg\n",
       "rater1                              0\n",
       "rater2                              0\n",
       "refNum                             66\n",
       "refCountry                          4\n",
       "Alpha_3                           LUX\n",
       "meanIAT                      0.325185\n",
       "nIAT                              127\n",
       "seIAT                      0.00329681\n",
       "meanExp                      0.538462\n",
       "nExp                              130\n",
       "seExp                       0.0137522\n",
       "Name: 1200, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.ix[1200,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All features for Toni Kroos - ref 66 - dyad. The column $\\texttt{games}$ stands for the number of games in the player-referee dyad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need all the features for our purposes. We can drop the features like $\\texttt{playerShort}$, $\\texttt{club}$, $\\texttt{height}$, $\\texttt{photoID}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.drop(data.columns[[0,1,2,5,6,7,8,9,10,11,12,13,16]],1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#transform birthday to age:\n",
    "#season: 2012-2013, so at the end it was 2013\n",
    "data['age'] = data['birthday'].apply(lambda x:2013- int(str(x)[-4:]))\n",
    "#we can now drop the birthday column\n",
    "data.drop('birthday',1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rater1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rater2</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1   2   3   4     5     6    7     8    9    10   11   12  \\\n",
       "rater1  0.25  0.75 NaN NaN NaN  0.25  0.00  1.0  0.25  0.0  0.0  0.5  0.0   \n",
       "rater2  0.50  0.75 NaN NaN NaN  0.00  0.25  1.0  0.25  0.0  0.0  0.5  0.0   \n",
       "\n",
       "         13    14   15   16   17   18    19  \n",
       "rater1  0.0  0.00  0.0  0.5  0.0  0.0  0.00  \n",
       "rater2  0.0  0.25  0.0  0.5  0.0  0.0  0.25  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.ix[:19,['rater1','rater2']].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05831882267033646, 0.011343119350169325)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(abs(data.ix[:,'rater1']-data.ix[:,'rater2'])),np.var(abs(data.ix[:,'rater1']-data.ix[:,'rater2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've looked at a small cut of the data set and the two raters do disagree occasionally by $0.25$. Bhe overall disagreement is relativley low with $0.058\\pm0.011$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14659517352836443"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(np.isnan(data.ix[:,'rater1']))/len(data.ix[:,'rater1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Rightarrow$ So around $15\\%$ of the instances don't have a picture attached to them. But those must not be all individual players but only individual dyads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['England' 'France' 'Germany' 'Spain']\n"
     ]
    }
   ],
   "source": [
    "leagues=np.unique(data.ix[:,'leagueCountry'])\n",
    "print(leagues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only the four leagues above in the data set. So a One-Hot could be the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>England</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>France</td>\n",
       "      <td>[0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0             1\n",
       "0  England  [1, 0, 0, 0]\n",
       "1   France  [0, 1, 0, 0]\n",
       "2  Germany  [0, 0, 1, 0]\n",
       "3    Spain  [0, 0, 0, 1]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([leagues,np.identity(4,dtype=int)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create column for each country, set 1 if player is playing in that league and 0 if not\n",
    "for country in leagues:\n",
    "    data[country]=data['leagueCountry'].apply(lambda x:int(country==x))\n",
    "#we can now drop the leagueCountry column\n",
    "data.drop('leagueCountry',1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression\n",
    "$$\\sum_{j=1}^DX_{ij}\\beta_j=y_i,\\ (\\mathbb N \\ni i\\leq N)$$\n",
    "$$\\Rightarrow\\mathbf X\\mathbf \\beta=\\mathbf y,\\ (\\text{matrices})$$\n",
    "$$\\hat{\\mathbf {\\beta}}= \\left(\\mathbf{X^TX}\\right)^{-1}\\mathbf{X^T y}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linearReg(x,y):\n",
    "    '''\n",
    "    Takes centralized data and finds the best beta (Dx1) vector\n",
    "    x: (NxD) matrix with data\n",
    "    y: (Nx1) vector with labels\n",
    "    '''\n",
    "    #centralize data:\n",
    "    x=x-np.mean(x)\n",
    "    y=y-np.mean(y)\n",
    "    print(x.T,y)\n",
    "    #calculate the moore penrose pseudo inverse:\n",
    "    xPlus=np.linalg.pinv(x)\n",
    "    return xPlus@y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    pass\n",
    "\n",
    "class Tree:\n",
    "    def __init__(self):\n",
    "        self.root = Node()\n",
    "    \n",
    "    def find_leaf(self, x):\n",
    "        node = self.root\n",
    "        while hasattr(node, \"feature\"):\n",
    "            j = node.feature\n",
    "            if x[j] <= node.threshold:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#since our solution to the 4th exercise was not working we took the solution from moodle and adjusted it \n",
    "class RegressionTree(Tree):\n",
    "    def __init__(self):\n",
    "        super(DecisionTree, self).__init__()\n",
    "        \n",
    "    def train(self, data, labels, n_min=20):\n",
    "        '''\n",
    "        data: the feature matrix for all digits\n",
    "        labels: the corresponding ground-truth responses\n",
    "        n_min: termination criterion (don't split if a node contains fewer instances)\n",
    "        '''\n",
    "        N, D = data.shape\n",
    "        D_try = int(np.sqrt(D)) # how many features to consider for each split decision\n",
    "\n",
    "        # initialize the root node\n",
    "        self.root.data = data\n",
    "        self.root.labels = labels\n",
    "        \n",
    "        #put root in stack\n",
    "        stack = [self.root]\n",
    "        while len(stack):\n",
    "            node = stack.pop()\n",
    "            n = node.data.shape[0] # number of instances in present node\n",
    "            if n >= n_min:\n",
    "                # Call 'make_decision_split_node()' with 'D_try' randomly selected \n",
    "                # feature indices. This turns 'node' into a split node\n",
    "                # and returns the two children, which must be placed on the 'stack'.\n",
    "                \n",
    "                perm = np.random.permutation(D)   # permute D indices\n",
    "                left, right = make_decision_split_node(node, perm[:D_try]) #select :D_try of permuted indices\n",
    "                                                       #for 'make_decision_split_node()'\n",
    "                # put children in stack\n",
    "                stack.append(left)\n",
    "                stack.append(right)\n",
    "            else:\n",
    "                # Call 'make_decision_leaf_node()' to turn 'node' into a leaf node.\n",
    "                make_decision_leaf_node(node)\n",
    "                \n",
    "    def predict(self, x):\n",
    "        leaf = self.find_leaf(x)\n",
    "        # compute p(y | x)\n",
    "        return leaf.response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_regression_split_node(node, N, feature_indices):\n",
    "    '''\n",
    "    node: the node to be split\n",
    "    feature_indices: a numpy array of length 'D_try', containing the feature \n",
    "                     indices to be considered in the present split\n",
    "    '''\n",
    "    n, D = node.data.shape\n",
    "\n",
    "    # find best feature j (among 'feature_indices') and best threshold t for the split\n",
    "    e_min = 1e100\n",
    "    j_min, t_min = 0, 0\n",
    "    for j in feature_indices:\n",
    "        # remove duplicate features\n",
    "        dj = np.sort(np.unique(node.data[:,j]))\n",
    "        # compute candidate thresholds in the middle between consecutive feature values\n",
    "        tj = 0.5 * (dj[1:] + dj[:-1]) \n",
    "        # each candidate threshold we need to compute squared error of the resulting children node\n",
    "        for t in tj:\n",
    "            left_indices = node.data[:,j] <= t\n",
    "            nl = np.sum(left_indices)\n",
    "            ll = node.labels[left_indices]\n",
    "            el = np.sum(np.square(ll-np.mean(ll)))/nl\n",
    "            nr = n - nl\n",
    "            lr = node.labels[node.data[:,j] > t]\n",
    "            er = np.sum(np.square(lr-np.mean(lr)))/nl\n",
    "            # choose the the best threshold that minimizes sum of the squared error.\n",
    "            if el + er < e_min:\n",
    "                e_min = el + er\n",
    "                j_min = j\n",
    "                t_min = t\n",
    "\n",
    "\n",
    "    # create children\n",
    "    left = Node()\n",
    "    right = Node()\n",
    "    \n",
    "    # initialize 'left' and 'right' with the data subsets and labels\n",
    "    # according to the optimal split found above\n",
    "    left.data = node.data[node.data[:,j_min] <= t_min, :]\n",
    "    left.labels = node.labels[node.data[:,j_min] <= t_min]\n",
    "    right.data = node.data[node.data[:,j_min] > t_min, :]\n",
    "    right.labels = node.labels[node.data[:,j_min] > t_min]\n",
    "\n",
    "    # turn the current 'node' into a split node\n",
    "    # (store children and split condition)\n",
    "    node.left = left\n",
    "    node.right = right\n",
    "    node.feature = j_min\n",
    "    node.threshold = t_min\n",
    "\n",
    "    # return the children (to be placed on the stack)\n",
    "    return left, right    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_regression_leaf_node(node, N):\n",
    "    '''\n",
    "    node: the node to become a leaf\n",
    "    '''\n",
    "    node.N = node.labels.shape[0]\n",
    "    node.response = np.sum(node.labels) / node.N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#forest\n",
    "class Forest:\n",
    "    def __init__(self,n):\n",
    "        # create n instances of Densiry tree \n",
    "        self.trees = [RegressionTree() for i in range(n)]\n",
    "    \n",
    "    def train(self, data, target, n_min=20):\n",
    "        # train all trees\n",
    "        for i, tree in enumerate(self.trees):\n",
    "            tree.train(data, target, n_min)\n",
    "            \n",
    "    def predict(self, x):\n",
    "        # return the digit for the DensityTree that maximizes p(x | y) * p(y)\n",
    "        return np.mean([tree.predict(x) for tree in self.trees])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: \n",
    "1. get x and y from the data set\n",
    "2. test the code\n",
    "3. do we need centralized data for the forest?\n",
    "4. determine the squared test errors by means of cross-validation\n",
    "5. how to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Answering the Research Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
