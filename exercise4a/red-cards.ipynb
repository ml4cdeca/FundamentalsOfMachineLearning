{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4a\n",
    "## 3 Red Cards Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1  Loading and Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load data with pandas\n",
    "data=pd.read_csv('data/CrowdstormingDataJuly1st.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "playerShort                toni-kroos\n",
       "player                     Toni Kroos\n",
       "club                   Bayern MÃ¼nchen\n",
       "leagueCountry                 Germany\n",
       "birthday                   04.01.1990\n",
       "height                            182\n",
       "weight                             78\n",
       "position         Attacking Midfielder\n",
       "games                               1\n",
       "victories                           1\n",
       "ties                                0\n",
       "defeats                             0\n",
       "goals                               0\n",
       "yellowCards                         0\n",
       "yellowReds                          0\n",
       "redCards                            0\n",
       "photoID                     84724.jpg\n",
       "rater1                              0\n",
       "rater2                              0\n",
       "refNum                             66\n",
       "refCountry                          4\n",
       "Alpha_3                           LUX\n",
       "meanIAT                      0.325185\n",
       "nIAT                              127\n",
       "seIAT                      0.00329681\n",
       "meanExp                      0.538462\n",
       "nExp                              130\n",
       "seExp                       0.0137522\n",
       "Name: 1200, dtype: object"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.ix[1200,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All features for Toni Kroos - ref 66 - dyad. The column $\\texttt{games}$ stands for the number of games in the player-referee dyad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need all the features for our purposes. We can drop the features like $\\texttt{player}$, $\\texttt{club}$, $\\texttt{height}$, $\\texttt{photoID}$, $\\texttt{Alpha_3}$ and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.drop(data.columns[[0,1,2,5,6,7,9,10,11,12,13,16,21]],1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#transform birthday to age:\n",
    "#season: 2012-2013, so at the end it was 2013\n",
    "data['age'] = data['birthday'].apply(lambda x:2013- int(str(x)[-4:]))\n",
    "#we can now drop the birthday column\n",
    "data.drop('birthday',1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rater1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rater2</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1   2   3   4     5     6    7     8    9    10   11   12  \\\n",
       "rater1  0.25  0.75 NaN NaN NaN  0.25  0.00  1.0  0.25  0.0  0.0  0.5  0.0   \n",
       "rater2  0.50  0.75 NaN NaN NaN  0.00  0.25  1.0  0.25  0.0  0.0  0.5  0.0   \n",
       "\n",
       "         13    14   15   16   17   18    19  \n",
       "rater1  0.0  0.00  0.0  0.5  0.0  0.0  0.00  \n",
       "rater2  0.0  0.25  0.0  0.5  0.0  0.0  0.25  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.ix[:19,['rater1','rater2']].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05831882267033646, 0.011343119350169325)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(abs(data.ix[:,'rater1']-data.ix[:,'rater2'])),np.var(abs(data.ix[:,'rater1']-data.ix[:,'rater2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've looked at a small cut of the data set and the two raters do disagree occasionally by $0.25$. Bhe overall disagreement is relativley low with $0.058\\pm0.011$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14659517352836443"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(np.isnan(data.ix[:,'rater1']))/len(data.ix[:,'rater1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Rightarrow$ So around $15\\%$ of the instances don't have a picture attached to them. But those must not be all individual players but only individual dyads. But all those instances don't help our case so we will drop those instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#drop dyads with no skin color rating\n",
    "data.drop(data.index[np.where(np.isnan(data['rater1']))],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['England' 'France' 'Germany' 'Spain']\n"
     ]
    }
   ],
   "source": [
    "leagues=np.unique(data.ix[:,'leagueCountry'])\n",
    "print(leagues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only the four leagues above in the data set. So a One-Hot could be the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>England</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>France</td>\n",
       "      <td>[0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0             1\n",
       "0  England  [1, 0, 0, 0]\n",
       "1   France  [0, 1, 0, 0]\n",
       "2  Germany  [0, 0, 1, 0]\n",
       "3    Spain  [0, 0, 0, 1]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([leagues,np.identity(4,dtype=int)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create column for each country, set 1 if player is playing in that league and 0 if not\n",
    "for country in leagues:\n",
    "    data[country]=data['leagueCountry'].apply(lambda x:int(country==x))\n",
    "#we can now drop the leagueCountry column\n",
    "data.drop('leagueCountry',1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calculate labels...\n",
    "labels=(data['yellowReds']+data['redCards'])/data['games']\n",
    "#...and drop all card related columns\n",
    "data.drop(data.columns[:3],1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rater1</th>\n",
       "      <th>rater2</th>\n",
       "      <th>refNum</th>\n",
       "      <th>refCountry</th>\n",
       "      <th>meanIAT</th>\n",
       "      <th>nIAT</th>\n",
       "      <th>seIAT</th>\n",
       "      <th>meanExp</th>\n",
       "      <th>nExp</th>\n",
       "      <th>seExp</th>\n",
       "      <th>age</th>\n",
       "      <th>England</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.326391</td>\n",
       "      <td>712.0</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.396000</td>\n",
       "      <td>750.0</td>\n",
       "      <td>0.002696</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.203375</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.010875</td>\n",
       "      <td>-0.204082</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.061504</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.325185</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.003297</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.013752</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.325185</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.003297</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.013752</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.325185</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.003297</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.013752</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rater1  rater2  refNum  refCountry   meanIAT   nIAT     seIAT   meanExp  \\\n",
       "0    0.25    0.50       1           1  0.326391  712.0  0.000564  0.396000   \n",
       "1    0.75    0.75       2           2  0.203375   40.0  0.010875 -0.204082   \n",
       "5    0.25    0.00       4           4  0.325185  127.0  0.003297  0.538462   \n",
       "6    0.00    0.25       4           4  0.325185  127.0  0.003297  0.538462   \n",
       "7    1.00    1.00       4           4  0.325185  127.0  0.003297  0.538462   \n",
       "\n",
       "    nExp     seExp  age  England  France  Germany  Spain  \n",
       "0  750.0  0.002696   30        0       0        0      1  \n",
       "1   49.0  0.061504   31        0       1        0      0  \n",
       "5  130.0  0.013752   34        1       0        0      0  \n",
       "6  130.0  0.013752   28        1       0        0      0  \n",
       "7  130.0  0.013752   27        1       0        0      0  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#that's how the data looks now\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression\n",
    "$$\\sum_{j=1}^DX_{ij}\\beta_j=y_i,\\ (\\mathbb N \\ni i\\leq N)$$\n",
    "$$\\Rightarrow\\mathbf X\\mathbf \\beta=\\mathbf y,\\ (\\text{matrices})$$\n",
    "$$\\hat{\\mathbf {\\beta}}= \\left(\\mathbf{X^TX}\\right)^{-1}\\mathbf{X^T y}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class linearReg:       \n",
    "    def train(slef,x,y):\n",
    "        '''\n",
    "        Takes centralized data and finds the best beta (Dx1) vector\n",
    "        x: (NxD) matrix with data\n",
    "        y: (Nx1) vector with labels\n",
    "        '''\n",
    "        #centralize data:\n",
    "        x=x-np.mean(x)\n",
    "        y=y-np.mean(y)\n",
    "        #calculate the moore penrose pseudo inverse:\n",
    "        xPlus=np.linalg.pinv(x)\n",
    "        self.beta=xPlus@y\n",
    "        \n",
    "    def predict(self,x):\n",
    "        return self.beta@x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    pass\n",
    "\n",
    "class Tree:\n",
    "    def __init__(self):\n",
    "        self.root = Node()\n",
    "    \n",
    "    def find_leaf(self, x):\n",
    "        node = self.root\n",
    "        while hasattr(node, \"feature\"):\n",
    "            j = node.feature\n",
    "            if x[j] <= node.threshold:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#since our solution to the 4th exercise was not working we took the solution from moodle and adjusted it \n",
    "class RegressionTree(Tree):\n",
    "    def __init__(self):\n",
    "        super(RegressionTree, self).__init__()\n",
    "        \n",
    "    def train(self, data, labels, n_min=20):\n",
    "        '''\n",
    "        data: the feature matrix for all digits\n",
    "        labels: the corresponding ground-truth responses\n",
    "        n_min: termination criterion (don't split if a node contains fewer instances)\n",
    "        '''\n",
    "        N, D = data.shape\n",
    "        D_try = int(np.sqrt(D)) # how many features to consider \n",
    "\n",
    "        # initialize the root node\n",
    "        self.root.data = data\n",
    "        self.root.labels = labels\n",
    "        \n",
    "        #put root in stack\n",
    "        stack = [self.root]\n",
    "        while len(stack):\n",
    "            node = stack.pop()\n",
    "            n = node.data.shape[0] # number of instances in present node\n",
    "            if n >= n_min:\n",
    "                # Call 'make_regression_split_node()' with 'D_try' randomly selected \n",
    "                # feature indices. This turns 'node' into a split node\n",
    "                # and returns the two children, which must be placed on the 'stack'.\n",
    "                \n",
    "                perm = np.random.permutation(D)   # permute D indices\n",
    "                left, right = make_regression_split_node(node, perm[:D_try]) #select :D_try of permuted indices\n",
    "                                                       #for 'make_regression_split_node()'\n",
    "                # put children in stack\n",
    "                stack.append(left)\n",
    "                stack.append(right)\n",
    "            else:\n",
    "                # Call 'make_regression_leaf_node()' to turn 'node' into a leaf node.\n",
    "                make_regression_leaf_node(node)\n",
    "                \n",
    "    def predict(self, x):\n",
    "        leaf = self.find_leaf(x)\n",
    "        # compute p(y | x)\n",
    "        return leaf.response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_regression_split_node(node, feature_indices):\n",
    "    '''\n",
    "    node: the node to be split\n",
    "    feature_indices: a numpy array of length 'D_try', containing the feature \n",
    "                     indices to be considered in the present split\n",
    "    '''\n",
    "    n, D = node.data.shape\n",
    "\n",
    "    # find best feature j (among 'feature_indices') and best threshold t for the split\n",
    "    e_min = 1e100\n",
    "    j_min, t_min = 0, 0\n",
    "    for j in feature_indices:\n",
    "        # remove duplicate features\n",
    "        dj = np.sort(np.unique(node.data[:,j]))\n",
    "        # compute candidate thresholds in the middle between consecutive feature values\n",
    "        tj = 0.5 * (dj[1:] + dj[:-1]) \n",
    "        # each candidate threshold we need to compute squared error of the resulting children node\n",
    "        for t in tj:\n",
    "            left_indices = node.data[:,j] <= t\n",
    "            nl = np.sum(left_indices)\n",
    "            ll = node.labels[left_indices]\n",
    "            el = np.sum(np.square(ll-np.mean(ll)))/nl\n",
    "            nr = n - nl\n",
    "            lr = node.labels[node.data[:,j] > t]\n",
    "            er = np.sum(np.square(lr-np.mean(lr)))/nl\n",
    "            # choose the the best threshold that minimizes sum of the squared error.\n",
    "            if el + er < e_min:\n",
    "                e_min = el + er\n",
    "                j_min = j\n",
    "                t_min = t\n",
    "\n",
    "\n",
    "    # create children\n",
    "    left = Node()\n",
    "    right = Node()\n",
    "    \n",
    "    # initialize 'left' and 'right' with the data subsets and labels\n",
    "    # according to the optimal split found above\n",
    "    left.data = node.data[node.data[:,j_min] <= t_min, :]\n",
    "    left.labels = node.labels[node.data[:,j_min] <= t_min]\n",
    "    right.data = node.data[node.data[:,j_min] > t_min, :]\n",
    "    right.labels = node.labels[node.data[:,j_min] > t_min]\n",
    "\n",
    "    # turn the current 'node' into a split node\n",
    "    # (store children and split condition)\n",
    "    node.left = left\n",
    "    node.right = right\n",
    "    node.feature = j_min\n",
    "    node.threshold = t_min\n",
    "\n",
    "    # return the children (to be placed on the stack)\n",
    "    return left, right    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_regression_leaf_node(node):\n",
    "    '''\n",
    "    node: the node to become a leaf\n",
    "    '''\n",
    "    node.N = node.labels.shape[0]\n",
    "    node.response = np.sum(node.labels) / node.N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#forest\n",
    "class Forest:\n",
    "    def __init__(self,n=10):\n",
    "        # create n instances of Regression tree \n",
    "        self.trees = [RegressionTree() for i in range(n)]\n",
    "    \n",
    "    def train(self, data, target, n_min=20):\n",
    "        # train all trees\n",
    "        for i, tree in enumerate(self.trees):\n",
    "            tree.train(data, target, n_min)\n",
    "            \n",
    "    def predict(self, x):\n",
    "        # return the digit for the DensityTree that maximizes p(x | y) * p(y)\n",
    "        return np.mean([tree.predict(x) for tree in self.trees])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#crossvalidation\n",
    "X=np.array(data)\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "def cross_validation(methode,num_sample=10):\n",
    "    \"\"\"\n",
    "    Measure the correct accuracy with cross validation\n",
    "    methode: class Forest or linearReg or similar\n",
    "    \"\"\"\n",
    "    mean_rate = np.zeros(num_sample)\n",
    "    for i in range(num_sample):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X,labels, test_size=0.33, random_state=None)\n",
    "        cl=None\n",
    "        f=methode()\n",
    "        f.train(x_train,y_train)\n",
    "        predicted_labels = f.predict(x_test)\n",
    "        mean_rate[i] = np.mean(predicted_labels == y_test)\n",
    "    \n",
    "    print(methode.__name__,\"Mean Accuracy Cross Validation: %f +/- %f\"%(np.mean(mean_rate), np.std(mean_rate)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "SVD did not converge",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-186-757412c331bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m#test models:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinearReg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-183-5aacff2fe17c>\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(methode, num_sample)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mcl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mpredicted_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mmean_rate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_labels\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-185-06702b2b010e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(slef, x, y)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[1;31m#calculate the moore penrose pseudo inverse:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mxPlus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpinv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxPlus\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\lukbl\\AppData\\Roaming\\Python\\Python36\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36mpinv\u001b[0;34m(a, rcond)\u001b[0m\n\u001b[1;32m   1870\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1871\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1872\u001b[0;31m     \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1873\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1874\u001b[0m     \u001b[1;31m# discard small singular values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\lukbl\\AppData\\Roaming\\Python\\Python36\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv)\u001b[0m\n\u001b[1;32m   1560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m         \u001b[0msignature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'D->DdD'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'd->ddd'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1562\u001b[0;31m         \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m         \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_realType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\lukbl\\AppData\\Roaming\\Python\\Python36\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_svd_nonconvergence\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_svd_nonconvergence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[1;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SVD did not converge\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_lstsq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: SVD did not converge"
     ]
    }
   ],
   "source": [
    "#test models:\n",
    "cross_validation(linearReg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: \n",
    "1. ~~get x and y from the data set~~\n",
    "2. test the code\n",
    "3. do we need centralized data for the forest?\n",
    "4. determine the squared test errors by means of cross-validation\n",
    "5. ~~how to handle missing data?~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Answering the Research Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#permutation test\n",
    "def shuffleSkinColors(data):\n",
    "    newData=data.copy()\n",
    "    seed=np.random.randint(2e9)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(newData['rater1'].values)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(newData['rater2'].values)\n",
    "    return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
