{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# base classes\n",
    "\n",
    "class Node:\n",
    "    pass\n",
    "\n",
    "class Tree:\n",
    "    def __init__(self):\n",
    "        self.root = Node()\n",
    "    \n",
    "    def find_leaf(self, x):\n",
    "        node = self.root\n",
    "        while hasattr(node, \"feature\"):\n",
    "            j = node.feature\n",
    "            if x[j] <= node.threshold:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DensityTree(Tree):\n",
    "    def __init__(self):\n",
    "        super(DensityTree, self).__init__()\n",
    "        \n",
    "    def train(self, data, prior):\n",
    "        '''\n",
    "        data: the feature matrix for the digit under consideration\n",
    "        prior: the prior probability of this digit\n",
    "        '''\n",
    "        self.prior = prior\n",
    "        N, D = data.shape\n",
    "        D_try = int(np.sqrt(D)) # number of features to consider for each split decision\n",
    "\n",
    "        # filter features and initialize bounding box\n",
    "        # (If m[j] == M[j] for some j, the bounding box has zero volume, \n",
    "        #  causing divide-by-zero later on. We must ignore these features\n",
    "        #  and adjust the bounding box accordingly.)\n",
    "        m, M = np.min(data, axis=0), np.max(data, axis=0)\n",
    "        valid_features   = np.where(m != M)[0]\n",
    "        invalid_features = np.where(m == M)[0]\n",
    "        M[invalid_features] = m[invalid_features] + 1\n",
    "\n",
    "        # initialize the root node\n",
    "        self.root.data = data\n",
    "        self.root.box = m.copy(), M.copy()\n",
    "        stack = [self.root]\n",
    "\n",
    "        n_min = 20 # termination criterion: don't split if node contains fewer instances\n",
    "        while len(stack):\n",
    "            node = stack.pop()\n",
    "            n = node.data.shape[0] # number of instances in present node\n",
    "            if n >= n_min:\n",
    "                \n",
    "                # Call 'make_density_split_node()' with 'D_try' randomly selected \n",
    "                # indices from 'valid_features'. This turns 'node' into a split node\n",
    "                # and returns the two children, which must be placed on the 'stack'.\n",
    "                #choose randomly D_try elements from valid_features\n",
    "                feature_indices=valid_features[np.random.permutation(len(valid_features))[:D_try]]\n",
    "                #put left and right to end of stack since pop() gets the last item\n",
    "                stack.extend(make_density_split_node(node,N,feature_indices)) \n",
    "                \n",
    "            else:\n",
    "                # Call 'make_density_leaf_node()' to turn 'node' into a leaf node.\n",
    "                node=make_density_leaf_node(node,N)\n",
    "\n",
    "    def predict(self, x):\n",
    "        leaf = self.find_leaf(x)        \n",
    "        # compute p(x | y) * p(y)\n",
    "        return leaf.response*self.prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def volume(plus,minus):\n",
    "    '''\n",
    "    minus: numpy array of all x^-\n",
    "    plus:       -''-          x^+\n",
    "    '''\n",
    "    #return volume\n",
    "    return np.prod(plus-minus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(N, m ,M , x_lambda, x_rho, S_lambda, S_rho, j):\n",
    "    m_lambda, m_rho, M_lambda, M_rho = m.copy(), m.copy(), M.copy(), M.copy()\n",
    "    m_lambda[j], m_rho[j], M_lambda[j], M_rho[j] = x_lambda[0], x_rho[0], x_lambda[1], x_rho[1]\n",
    "    V_lambda = volume(M_lambda, m_lambda)\n",
    "    V_rho = volume(M_rho, m_rho)\n",
    "    looErr = len(S_lambda)/(N * V_lambda)*(len(S_lambda)/N - 2 * (len(S_lambda) - 1) / (N - 1)) +\\\n",
    "             len(S_rho)   /(N * V_rho)*   (len(S_rho)   /N - 2 * (len(S_rho) - 1)    / (N - 1))\n",
    "    return looErr\n",
    "  \n",
    "def make_density_split_node(node, N, feature_indices):\n",
    "    '''\n",
    "    node: the node to be split\n",
    "    N:    the total number of training instances for the current class\n",
    "    feature_indices: a numpy array of length 'D_try', containing the feature \n",
    "                     indices to be considered in the present split\n",
    "    '''\n",
    "    n, D = node.data.shape\n",
    "    m, M = node.box\n",
    "\n",
    "    # find best feature j (among 'feature_indices') and best threshold t for the split\n",
    "    # Hint: For each feature considered, first remove duplicate feature values using \n",
    "    # 'np.unique()'. Describe here why this is necessary.\n",
    "    best_splits = []\n",
    "    best_scores = []\n",
    "    for j in feature_indices:      \n",
    "            sorted_data = np.sort(node.data.T[j])\n",
    "            # same argumentation\n",
    "            # filter features and initialize bounding box\n",
    "            # (If m[j] == M[j] for some j, the bounding box has zero volume, \n",
    "            #  causing divide-by-zero later on. We must ignore these features\n",
    "            sorted_data = np.unique(sorted_data)\n",
    "            x_j = np.insert(sorted_data, 0, 0)\n",
    "            x_j_plus = np.insert(sorted_data, len(sorted_data), 0)\n",
    "            t_j = ((x_j + x_j_plus)/2)[1:-2]\n",
    "            scores = []\n",
    "            for t in t_j:\n",
    "                S_lambda = sorted_data[sorted_data <= t]\n",
    "                x_lambda = S_lambda[[0,-1]]\n",
    "                S_rho = sorted_data[sorted_data > t]\n",
    "                x_rho = S_rho[[0,-1]]\n",
    "                scores.append(score(N, m ,M , x_lambda, x_rho, S_lambda, S_rho, j))\n",
    "            if scores==[]:\n",
    "                continue\n",
    "            best_splits.append(t_j[np.argmin(scores)])\n",
    "            best_scores.append(min(scores))\n",
    "    \n",
    "    index=np.argmin(best_scores)\n",
    "    split_feature = feature_indices[index]\n",
    "    split_threshold = best_scores[index]\n",
    "    threshold = best_splits[index]\n",
    "    \n",
    "    # create children, data yet to be added, only definition of boxes\n",
    "    left = Node()\n",
    "    right = Node()\n",
    "    \n",
    "    # initialize 'left' and 'right' with the data subsets and bounding boxes\n",
    "    # according to the optimal split found above\n",
    "    # split data into left.data and right.data\n",
    "    subData=node.data[:,split_feature] #vllt index?\n",
    "    indices=np.argsort(subData)\n",
    "    splitIndex=np.argwhere(subData[indices]>=split_threshold)[0][0]\n",
    "    \n",
    "    # data smaller than threshold into left \n",
    "    left.data=node.data[indices,:][:splitIndex,:]\n",
    "    right.data =node.data[indices,:][splitIndex:,:]\n",
    "    \n",
    "    # set left.box and right.box:\n",
    "    m_rho, M_lambda = m.copy(), M.copy()\n",
    "    m_rho[split_feature], M_lambda[split_feature] = threshold, threshold\n",
    "    left.box = (m, M_lambda)\n",
    "    right.box = (m_rho, M)\n",
    "    \n",
    "    # turn the current 'node' into a split node\n",
    "    # (store children and split condition)\n",
    "    node.left,node.right=left,right\n",
    "    node.feature=split_feature\n",
    "\n",
    "    # return the children (to be placed on the stack)\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_density_leaf_node(node, N):\n",
    "    '''\n",
    "    node: the node to become a leaf\n",
    "    N:    the total number of training instances for the current class\n",
    "    '''\n",
    "    # compute and store leaf response\n",
    "    # compute volume Vl\n",
    "    Vl=volume(*node.box)\n",
    "    # response\n",
    "    response = node.data.shape[0]/(N*Vl)\n",
    "    node=Node()\n",
    "    node.response=response\n",
    "    return node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecisionTree(Tree):\n",
    "    def __init__(self):\n",
    "        super(DecisionTree, self).__init__()\n",
    "        \n",
    "    def train(self, data, labels):\n",
    "        '''\n",
    "        data: the feature matrix for all digits\n",
    "        labels: the corresponding ground-truth responses\n",
    "        '''\n",
    "        N, D = data.shape\n",
    "        D_try = int(np.sqrt(D)) # how many features to consider for each split decision\n",
    "\n",
    "        # initialize the root node\n",
    "        self.root.data = data\n",
    "        self.root.labels = labels\n",
    "        stack = [self.root]\n",
    "\n",
    "        n_min = 20 # termination criterion: don't split if node contains fewer instances\n",
    "        while len(stack):\n",
    "            node = stack.pop()\n",
    "            n = node.data.shape[0] # number of instances in present node\n",
    "            if n >= n_min and not node_is_pure(node):\n",
    "                # Call 'make_decision_split_node()' with 'D_try' randomly selected \n",
    "                # feature indices. This turns 'node' into a split node\n",
    "                # and returns the two children, which must be placed on the 'stack'.\n",
    "                feature_indices=valid_features[np.random.permutation(len(valid_features))[:D_try]]\n",
    "                #put left and right to end of stack since pop() gets the last item\n",
    "                stack.extend(make_decision_split_node(node,N,feature_indices)) \n",
    "            else:\n",
    "                # Call 'make_decision_leaf_node()' to turn 'node' into a leaf node.\n",
    "                node=make_decision_leaf_node(node,N)\n",
    "                \n",
    "    def predict(self, x):\n",
    "        leaf = self.find_leaf(x)\n",
    "        # compute p(y | x)\n",
    "        return leaf.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score2(S_lambda, S_rho, sorted_labels):\n",
    "    labels_lambda = sorted_labels[:len(S_lambda)]\n",
    "    labels_rho = sorted_labels[len(S_lambda):]\n",
    "    labels = unique(sorted_labels)\n",
    "    N_lambda_k = []\n",
    "    N_rho_k =[]  \n",
    "    for lab in labels:\n",
    "        N_lambda_k.append(np.count_nonzero(labels_lambda == lab))\n",
    "        N_rho_k.append(np.count_nonzero(labels_rho == lab))\n",
    "    Err_lambda = len(S_lambda)*(1 - np.sum(np.square(N_lambda_k/len(S_lambda))))\n",
    "    Err_rho    = len(S_rho)   *(1 - np.sum(np.square(N_rho_k/len(S_rho))))\n",
    "    return Err_lambda + Err_rho\n",
    "\n",
    "def make_decision_split_node(node, feature_indices):\n",
    "    '''\n",
    "    node: the node to be split\n",
    "    feature_indices: a numpy array of length 'D_try', containing the feature \n",
    "                     indices to be considered in the present split\n",
    "    '''\n",
    "    n, D = node.data.shape\n",
    "\n",
    "    # find best feature j (among 'feature_indices') and best threshold t for the split\n",
    "    best_splits = []\n",
    "    best_scores = []\n",
    "    for j in feature_indices:\n",
    "        sortingIndices=np.argsort(node.data.T[j])\n",
    "        sorted_data = node.data.T[j][sortingIndices]\n",
    "        sorted_labels = node.labels[sortingIndices]\n",
    "        #to do: filter sorted_data,sorted_labels\n",
    "        x_j = np.insert(sorted_data, 0, 0)\n",
    "        x_j_plus = np.insert(sorted_data, len(sorted_data), 0)\n",
    "        t_j = ((x_j + x_j_plus)/2)[1:-2]\n",
    "        scores = []\n",
    "        for t in t_j:\n",
    "            S_lambda = sorted_data[sorted_data <= t]\n",
    "            x_lambda = S_lambda[[0,-1]]\n",
    "            S_rho = sorted_data[sorted_data > t]\n",
    "            x_rho = S_rho[[0,-1]]\n",
    "            scores.append(score2(S_lambda, S_rho, sorted_labels))\n",
    "        best_splits.append(t_j[np.argmin(scores)])\n",
    "        best_scores.append(min(scores))\n",
    "    \n",
    "    index=np.argmin(best_scores)\n",
    "    split_feature = feature_indices[index]\n",
    "    split_threshold = best_scores[index]\n",
    "    threshold = best_splits[index]\n",
    "\n",
    "    \n",
    "    #just the same code as before:\n",
    "    # create children, data yet to be added, only definition of boxes\n",
    "    left = Node()\n",
    "    right = Node()\n",
    "    \n",
    "    # initialize 'left' and 'right' with the data subsets and bounding boxes\n",
    "    # according to the optimal split found above\n",
    "    # split data into left.data and right.data\n",
    "    subData=node.data[:,split_feature] #vllt index?\n",
    "    indices=np.argsort(subData)\n",
    "    splitIndex=np.argwhere(subData[indices]>=threshold)[0][0]\n",
    "    \n",
    "    # data smaller than threshold into left \n",
    "    left.data=node.data[indices,:][:splitIndex,:]\n",
    "    right.data =node.data[indices,:][splitIndex:,:]\n",
    "    \n",
    "    #split labels\n",
    "    left.labels=node.labels[indices][:splitIndex]\n",
    "    right.labels=node.labels[indices][splitIndex:]\n",
    "    \n",
    "    # set left.box and right.box:\n",
    "    m_rho, M_lambda = m.copy(), M.copy()\n",
    "    m_rho[split_feature], M_lambda[split_feature] = threshold, threshold\n",
    "    left.box = (m, M_lambda)\n",
    "    right.box = (m_rho, M)\n",
    "    \n",
    "    # turn the current 'node' into a split node\n",
    "    # (store children and split condition)\n",
    "    node.left,node.right=left,right\n",
    "    node.feature=split_feature\n",
    "\n",
    "    # return the children (to be placed on the stack)\n",
    "    return left, right  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_decision_leaf_node(node):\n",
    "    '''\n",
    "    node: the node to become a leaf\n",
    "    '''\n",
    "    # compute and store leaf response\n",
    "    # count number of instances in classes:\n",
    "    Nlk=np.bincount(node.labels)\n",
    "    node=Node()\n",
    "    node.response=Nlk/np.sum(Nlk)\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def node_is_pure(node):\n",
    "    '''\n",
    "    check if 'node' ontains only instances of the same digit\n",
    "    '''\n",
    "    return True if np.count_nonzero(np.bincount(node.labels)) else False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Density and Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read and prepare the digits data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import model_selection\n",
    "#load digits\n",
    "digits = load_digits ()\n",
    "data = digits [\"data\"]\n",
    "images = digits [\"images\"]\n",
    "target = digits [\"target\"]\n",
    "target_names = digits [\"target_names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:6: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:6: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:56: RuntimeWarning: invalid value encountered in greater_equal\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-96498f9276a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# train trees, plot training error confusion matrices, and comment on your results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDensityTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-0d5a3c3d698a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data, prior)\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfeature_indices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mD_try\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[1;31m#put left and right to end of stack since pop() gets the last item\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmake_density_split_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeature_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-4c6bb55479f2>\u001b[0m in \u001b[0;36mmake_density_split_node\u001b[0;34m(node, N, feature_indices)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0msubData\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msplit_feature\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#vllt index?\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0msplitIndex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[0msplit_threshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[1;31m# data smaller than threshold into left\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# train trees, plot training error confusion matrices, and comment on your results\n",
    "dens=DensityTree()\n",
    "dens.train(data[:40],.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-79d0c7ddc9e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not list"
     ]
    }
   ],
   "source": [
    "x=[10,2,3,5]\n",
    "print(x[[0,-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density and Decision Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DensityForest():\n",
    "    def __init__(self, n_trees):\n",
    "        # create ensemble\n",
    "        self.trees = [DensityTree() for i in range(n_trees)]\n",
    "    \n",
    "    def train(self, data, prior):\n",
    "        for tree in self.trees:\n",
    "            # train each tree, using a bootstrap sample of the data\n",
    "            ... # your code here\n",
    "\n",
    "    def predict(self, x):\n",
    "        # compute the ensemble prediction\n",
    "        return ... # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecisionForest():\n",
    "    def __init__(self, n_trees):\n",
    "        # create ensemble\n",
    "        self.trees = [DecisionTree() for i in range(n_trees)]\n",
    "    \n",
    "    def train(self, data, labels):\n",
    "        for tree in self.trees:\n",
    "            # train each tree, using a bootstrap sample of the data\n",
    "            ... # your code here\n",
    "\n",
    "    def predict(self, x):\n",
    "        # compute the ensemble prediction\n",
    "        return ... # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Density and Decision Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train forests (with 20 trees per forest), plot training error confusion matrices, and comment on your results\n",
    "... # your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
